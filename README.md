# Neuro-Symbolic Diffusion (NS-Diff)

**Official Implementation of "Neuro-Symbolic Diffusion: Bridging Interpretable Classification and Generative Verification via Manifold-Aligned Concepts"**

## ğŸ“‹ æ¦‚è¿°

NS-Diffæ˜¯ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶,å°†æ‰©æ•£æ¨¡å‹çš„æµå½¢å­¦ä¹ èƒ½åŠ›ä¸å¯å¾®ç¥ç»ç¬¦å·é€»è¾‘çš„æ¼”ç»ä¸¥è°¨æ€§ç›¸ç»“åˆã€‚é€šè¿‡ç«¯åˆ°ç«¯è®­ç»ƒ,å®ç°äº†é«˜ç²¾åº¦åˆ†ç±»å’Œå¯è§£é‡Šçš„ç”ŸæˆéªŒè¯ã€‚

### æ ¸å¿ƒåˆ›æ–°

1. **Semantic Manifold Alignment (SMA)**: é€šè¿‡Jacobianæ­£äº¤æ­£åˆ™åŒ–,å°†æ½œåœ¨å­æ¢¯åº¦æŠ•å½±åˆ°æ­£äº¤çš„å¯è§£é‡Šæ¦‚å¿µåº¦é‡ç©ºé—´
2. **Differentiable Neuro-Symbolic Logic (DNSL)**: åŸºäºProduct T-Normsçš„å¯å¾®æ¨¡ç³Šé€»è¾‘,å®ç°æ˜¾å¼IF-THENè§„åˆ™çš„ç«¯åˆ°ç«¯ä¼˜åŒ–
3. **Generative Counterfactual Verification**: é€šè¿‡åˆæˆå› æœå¹²é¢„,è§†è§‰åŒ–éªŒè¯æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹

## ğŸ”§ å®‰è£…

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- CUDA 11.0+ (ç”¨äºGPUè®­ç»ƒ)
- 16GB+ RAM (æ¨è32GB)

### å¿«é€Ÿå®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/your-repo/ns-diff.git
cd ns-diff

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n nsdiff python=3.9
conda activate nsdiff

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å®‰è£…åŸºçº¿æ¨¡å‹ä¾èµ– (å¯é€‰)
# Concept Bottleneck Models
git clone https://github.com/yewsiang/ConceptBottleneck.git
cd ConceptBottleneck && pip install -e . && cd ..
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
ns-diff/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ ns_diff.py              # NS-Diffæ ¸å¿ƒå®ç°
â”‚   â””â”€â”€ baselines.py            # åŸºçº¿æ¨¡å‹ (ResNet, CBM, etc.)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ datasets.py             # æ•°æ®åŠ è½½å™¨ (Shapes3D, CelebA-HQ)
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ metrics.py              # è¯„ä¼°æŒ‡æ ‡ (MIG, ISR, etc.)
â”‚   â””â”€â”€ visualization.py        # å¯è§†åŒ–å·¥å…·
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ config.json             # å®éªŒé…ç½®
â”‚   â””â”€â”€ run_all_experiments.py  # å®Œæ•´å®éªŒè„šæœ¬
â”œâ”€â”€ train.py                    # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ requirements.txt            # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md                   # æœ¬æ–‡æ¡£
```

## ğŸ“Š æ•°æ®é›†å‡†å¤‡

### CelebA-HQ

1. ä¸‹è½½CelebA-HQæ•°æ®é›†:
```bash
# ä¸‹è½½å›¾åƒ
wget https://drive.google.com/file/d/1badu11NqxGf6qM3PTTooQDJvQbejgbTv/view

# ä¸‹è½½å±æ€§æ–‡ä»¶
wget https://drive.google.com/file/d/0B7EVK8r0v71pblRyaVFSWGxPY0U/view
```

2. æ•´ç†ç›®å½•ç»“æ„:
```
/path/to/celeba-hq/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ 00000.png
â”‚   â”œâ”€â”€ 00001.png
â”‚   â””â”€â”€ ...
â””â”€â”€ list_attr_celeba.txt
```

### Shapes3D

1. ä¸‹è½½Shapes3Dæ•°æ®é›†:
```bash
# ä»DeepMindä¸‹è½½
gsutil -m cp -r gs://3d-shapes/3dshapes.h5 /path/to/data/
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### è®­ç»ƒNS-Diff

```bash
python train.py \
    --model ns_diff \
    --dataset celeba-hq \
    --data_path /path/to/celeba-hq \
    --image_dir /path/to/celeba-hq/images \
    --attr_file /path/to/celeba-hq/list_attr_celeba.txt \
    --epochs 100 \
    --batch_size 32 \
    --learning_rate 1e-4 \
    --num_concepts 8 \
    --num_classes 2 \
    --lambda_cls 1.0 \
    --lambda_ortho 0.1 \
    --device cuda
```

### è®­ç»ƒåŸºçº¿æ¨¡å‹

#### ResNet-50
```bash
python train.py \
    --model resnet50 \
    --dataset celeba-hq \
    --data_path /path/to/celeba-hq \
    --image_dir /path/to/celeba-hq/images \
    --attr_file /path/to/celeba-hq/list_attr_celeba.txt \
    --epochs 100 \
    --batch_size 32
```

#### Standard CBM
```bash
python train.py \
    --model standard_cbm \
    --dataset celeba-hq \
    --data_path /path/to/celeba-hq \
    --image_dir /path/to/celeba-hq/images \
    --attr_file /path/to/celeba-hq/list_attr_celeba.txt \
    --num_concepts 8 \
    --epochs 100
```

## ğŸ§ª å¤ç°è®ºæ–‡å®éªŒ

### è¿è¡Œå®Œæ•´å®éªŒå¥—ä»¶

```bash
# 1. ä¿®æ”¹å®éªŒé…ç½®
vim experiments/config.json

# 2. è¿è¡Œæ‰€æœ‰å®éªŒ
python experiments/run_all_experiments.py --config experiments/config.json
```

è¿™å°†è‡ªåŠ¨è¿è¡Œ:
- åŸºçº¿å¯¹æ¯”å®éªŒ (Table 1)
- æ¶ˆèç ”ç©¶ (Table 1 åº•éƒ¨)
- Shapes3DéªŒè¯å®éªŒ
- ç”Ÿæˆåäº‹å®å¯è§†åŒ– (Figure 2)

### å•ç‹¬è¿è¡Œå®éªŒ

#### åŸºçº¿å¯¹æ¯”
```bash
# NS-Diff
python train.py --model ns_diff --dataset celeba-hq ...

# ResNet-50
python train.py --model resnet50 --dataset celeba-hq ...

# Standard CBM
python train.py --model standard_cbm --dataset celeba-hq ...

# Post-hoc CBM
python train.py --model posthoc_cbm --dataset celeba-hq ...

# DisDiff-FNNC
python train.py --model disdiff_fnnc --dataset celeba-hq ...
```

#### æ¶ˆèç ”ç©¶
```bash
# å®Œæ•´NS-Diff
python train.py --model ns_diff --lambda_cls 1.0 --lambda_ortho 0.1 ...

# w/o æ­£äº¤æ­£åˆ™åŒ–
python train.py --model ns_diff --lambda_cls 1.0 --lambda_ortho 0.0 ...

# å…¶ä»–æ¶ˆèå˜ä½“éœ€è¦ä¿®æ”¹ä»£ç 
```

## ğŸ“ˆ è¯„ä¼°å’Œå¯è§†åŒ–

### è®¡ç®—è¯„ä¼°æŒ‡æ ‡

```python
from evaluation.metrics import compute_metrics
from models.ns_diff_error import NSDiff
import torch

# åŠ è½½æ¨¡å‹
model = NSDiff(num_concepts=8, num_classes=2)
checkpoint = torch.load('checkpoints/best_model.pth')
model.load_state_dict(checkpoint['model_state_dict'])

# è®¡ç®—æŒ‡æ ‡
metrics = compute_metrics(
    concepts=predicted_concepts,
    labels=true_labels,
    model=model,
    test_loader=test_loader,
    device=device,
    ground_truth_factors=ground_truth_factors  # å¦‚æœå¯ç”¨
)

print(f"Accuracy: {metrics['accuracy']:.2f}%")
print(f"MIG: {metrics['mig']:.4f}")
print(f"ISR: {metrics['isr']:.2f}%")
```

### ç”Ÿæˆå¯è§†åŒ–

```python
from evaluation.visualization import (
    visualize_counterfactual_comparison,
    plot_performance_comparison,
    create_concept_intervention_grid
)

# åäº‹å®å¯¹æ¯”
visualize_counterfactual_comparison(
    original=original_images,
    counterfactual=counterfactual_images,
    concept_idx=2,
    concept_names=['Bangs', 'Beard', 'Smiling', ...],
    original_concepts=original_concepts,
    cf_concepts=cf_concepts,
    save_path='results/counterfactual.png'
)

# æ€§èƒ½å¯¹æ¯”
results = {
    'ResNet-50': {'accuracy': 90.2, 'mig': 0.0, 'isr': 0.0},
    'NS-Diff': {'accuracy': 89.3, 'mig': 0.78, 'isr': 91.4}
}
plot_performance_comparison(results, save_path='results/comparison.png')

# æ¦‚å¿µå¹²é¢„ç½‘æ ¼
create_concept_intervention_grid(
    model=model,
    image=test_image,
    concept_idx=0,
    concept_name='Bangs',
    num_steps=7,
    save_path='results/intervention_grid.png'
)
```

## ğŸ“Š é¢„æœŸç»“æœ

æ ¹æ®è®ºæ–‡,åœ¨CelebA-HQä¸Šçš„é¢„æœŸç»“æœ:

| Model | Acc (%) | MIG | ISR (%) |
|-------|---------|-----|---------|
| ResNet-50 | 90.2 | N/A | N/A |
| Standard CBM | 86.5 | 0.42 | 23.5 |
| Post-hoc CBM | 85.8 | 0.48 | N/A |
| DisDiff-FNNC | 87.1 | 0.55 | 65.2 |
| **NS-Diff (Ours)** | **89.3** | **0.78** | **91.4** |

æ¶ˆèç ”ç©¶ç»“æœ:

| Variant | Acc (%) | MIG | ISR (%) |
|---------|---------|-----|---------|
| NS-Diff | 89.3 | 0.78 | 91.4 |
| w/o SMA | 86.1 | 0.45 | 35.8 |
| w/o Ortho | 88.5 | 0.62 | 72.1 |
| w/o DNSL | 89.8 | 0.76 | 90.5 |

## ğŸ” æ ¸å¿ƒç®—æ³•è§£æ

### Algorithm 1: Neuro-Symbolic Manifold Alignment & Joint Training

```
è¾“å…¥: æ•°æ®é›† D = {(x, y)}, é¢„è®­ç»ƒæ‰©æ•£ç¼–ç å™¨ E_Ï†, è§£ç å™¨ D_Ïˆ
è¾“å‡º: ä¼˜åŒ–çš„SMAæŠ•å½±å™¨ P_Î¸, DNSLé€»è¾‘æƒé‡ W_rule

1. åˆå§‹åŒ– P_Î¸, W_rule
2. While not converged:
    // Phase 1: æµå½¢æ„ŸçŸ¥ä¸å¯¹é½
    z â† E_Ï†(x)                           # æå–æ½œåœ¨å­æ¢¯åº¦
    c â† P_Î¸(z)                           # æŠ•å½±åˆ°æ¦‚å¿µåº¦é‡ç©ºé—´
    
    // Phase 2: å‡ ä½•æ­£åˆ™åŒ– (Theorem 1)
    L_ortho â† âˆ‘_{iâ‰ j} â€–âˆ‡_z c_i Â· (âˆ‡_z c_j)^Tâ€–Â²_F
    
    // Phase 3: å¯å¾®é€»è¾‘æ¨ç† (DNSL)
    Î¼ â† exp(-(c - m)Â²/2ÏƒÂ²)               # è¯­ä¹‰æ¨¡ç³ŠåŒ–
    Î± â† âˆ_{kâˆˆI} Î¼_k                      # Product T-Normè§„åˆ™æ¨ç†
    Å· â† Softmax(W^T_rule Â· Î±)            # é€»è¾‘èšåˆ
    
    // Phase 4: ç«¯åˆ°ç«¯ä¼˜åŒ–
    L_cls â† CrossEntropy(y, Å·)
    L_total â† Î»_cls Â· L_cls + Î»_ortho Â· L_ortho
    Backward: âˆ‡L_total é€šè¿‡ Î± â†’ Î¼ â†’ c â†’ z åå‘ä¼ æ’­
    Update: Ï†, Î¸, W_rule
    
    // Phase 5: ç”ŸæˆéªŒè¯ (å‘¨æœŸæ€§)
    If iteration % N_check == 0:
        c' â† Intervene(c, target_concept)
        x_cf â† D_Ïˆ(c')                   # ç”Ÿæˆåäº‹å®
```

## ğŸ› ï¸ è‡ªå®šä¹‰å’Œæ‰©å±•

### æ·»åŠ æ–°çš„æ•°æ®é›†

```python
from data.datasets import Dataset
import torch

class CustomDataset(Dataset):
    def __init__(self, data_path, ...):
        # åŠ è½½æ•°æ®
        pass
    
    def __getitem__(self, idx):
        image = ...  # åŠ è½½å›¾åƒ
        target = ...  # ç±»åˆ«æ ‡ç­¾
        concepts = ...  # æ¦‚å¿µå‘é‡
        return image, target, concepts
```

### ä¿®æ”¹æ¦‚å¿µæ•°é‡

```python
# åœ¨è®­ç»ƒæ—¶æŒ‡å®š
python train.py \
    --model ns_diff \
    --num_concepts 12 \  # å¢åŠ åˆ°12ä¸ªæ¦‚å¿µ
    --num_classes 5      # 5ç±»åˆ†ç±»
```

### è°ƒæ•´æŸå¤±æƒé‡

æ ¹æ®ä»»åŠ¡ç‰¹æ€§è°ƒæ•´Î»_clså’ŒÎ»_ortho:

```bash
# æ›´æ³¨é‡åˆ†ç±»æ€§èƒ½
python train.py --lambda_cls 1.0 --lambda_ortho 0.05

# æ›´æ³¨é‡æ¦‚å¿µè§£è€¦
python train.py --lambda_cls 0.8 --lambda_ortho 0.2
```

## ğŸ› å¸¸è§é—®é¢˜

### Q1: CUDAå†…å­˜ä¸è¶³
```bash
# å‡å°æ‰¹æ¬¡å¤§å°
--batch_size 16

# æˆ–ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
--accumulation_steps 2
```

### Q2: è®­ç»ƒä¸æ”¶æ•›
- é™ä½å­¦ä¹ ç‡: `--learning_rate 5e-5`
- å¢åŠ æ­£åˆ™åŒ–: `--weight_decay 1e-4`
- è°ƒæ•´æŸå¤±æƒé‡: `--lambda_ortho 0.05`

### Q3: ISRåˆ†æ•°è¿‡ä½
- å¢åŠ æ­£äº¤æ­£åˆ™åŒ–æƒé‡: `--lambda_ortho 0.2`
- æ£€æŸ¥è§£ç å™¨è®­ç»ƒæ˜¯å¦å……åˆ†
- ç¡®ä¿æ¦‚å¿µå¯¹é½è´¨é‡

## ğŸ“ å¼•ç”¨

å¦‚æœä½ ä½¿ç”¨äº†æœ¬ä»£ç ,è¯·å¼•ç”¨:

```bibtex
@inproceedings{nsdiff2025,
  title={Neuro-Symbolic Diffusion: Bridging Interpretable Classification and Generative Verification via Manifold-Aligned Concepts},
  author={Anonymous},
  booktitle={Conference},
  year={2025}
}
```


Qickstart
# 1. å®‰è£…
pip install -r requirements.txt
python test_installation.py

# 2. å‡†å¤‡æ•°æ®
# ä¸‹è½½CelebA-HQå’ŒShapes3D

# 3. è®­ç»ƒNS-Diff
python train.py --model ns_diff --dataset celeba-hq \
    --data_path /path/to/data --epochs 100

# 4. è¿è¡Œå®Œæ•´å®éªŒ
python experiments/run_all_experiments.py

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®,è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»:
- GitHub Issues: [é¡¹ç›®Issuesé¡µé¢]
- Email: [your-email@domain.com]

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸ™ è‡´è°¢

- Concept Bottleneck Models (Koh et al., ICML 2020)
- Diffusion Models (Ho et al., NeurIPS 2020)
- Post-hoc CBM (Yuksekgonul et al., ICLR 2023)
- Shapes3D Dataset (DeepMind)
- CelebA-HQ Dataset (Nvidia)