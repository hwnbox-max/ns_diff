# NS-Diff é¡¹ç›®å®ç°æ¦‚è§ˆ

## ğŸ“š é¡¹ç›®ç»“æ„

æœ¬é¡¹ç›®å®Œæ•´å®ç°äº†è®ºæ–‡ "Neuro-Symbolic Diffusion: Bridging Interpretable Classification and Generative Verification via Manifold-Aligned Concepts" çš„æ‰€æœ‰æ ¸å¿ƒç®—æ³•å’Œå®éªŒã€‚

### æ ¸å¿ƒæ¨¡å—

#### 1. **models/ns_diff.py** - NS-Diffæ ¸å¿ƒå®ç°

åŒ…å«äº”ä¸ªä¸»è¦ç±»:

```python
# 1. DiffusionEncoder: æ‰©æ•£ç¼–ç å™¨ E_Ï†
#    - ä»å›¾åƒxæå–æ½œåœ¨è¡¨ç¤ºz
#    - åŸºäºU-Net bottleneckæ¶æ„
#    - æ•è·æ•°æ®æµå½¢çš„score function

# 2. SemanticManifoldAlignment (SMA): è¯­ä¹‰æµå½¢å¯¹é½ P_Î¸
#    - éçº¿æ€§MLPæŠ•å½±å™¨
#    - Jacobianæ­£äº¤æ­£åˆ™åŒ– (Theorem 1)
#    - å°†zæŠ•å½±åˆ°æ­£äº¤æ¦‚å¿µç©ºé—´c

# 3. DifferentiableNeuroSymbolicLogic (DNSL): å¯å¾®ç¥ç»ç¬¦å·é€»è¾‘
#    - é«˜æ–¯éš¶å±å‡½æ•° (Eq. 2)
#    - Product T-Normè§„åˆ™æ¨ç† (Eq. 3-4)
#    - Softmaxå»æ¨¡ç³ŠåŒ– (Eq. 5)

# 4. DiffusionDecoder: æ‰©æ•£è§£ç å™¨ D_Ïˆ
#    - ä»ä¿®æ”¹çš„æ¦‚å¿µc'ç”Ÿæˆåäº‹å®x'
#    - ç”¨äºç”ŸæˆéªŒè¯

# 5. NSDiff: å®Œæ•´æ¡†æ¶
#    - æ•´åˆæ‰€æœ‰æ¨¡å—
#    - å®ç°Algorithm 1çš„å®Œæ•´è®­ç»ƒæµç¨‹
#    - æä¾›åäº‹å®ç”Ÿæˆæ¥å£
```

**å…³é”®æ–¹æ³•**:
- `compute_jacobian_orthogonality_loss()`: å®ç°Eq. 1çš„Jacobianæ­£äº¤æ­£åˆ™åŒ–
- `fuzzify()`: å®ç°Eq. 2çš„è¯­ä¹‰æ¨¡ç³ŠåŒ–
- `product_tnorm()`: å®ç°Eq. 3çš„Product T-Normæ¨ç†
- `generate_counterfactual()`: ç”Ÿæˆåäº‹å®éªŒè¯
- `compute_total_loss()`: è®¡ç®—è”åˆæŸå¤± (Algorithm 1 Phase 4)

#### 2. **models/baselines.py** - åŸºçº¿æ¨¡å‹

å®ç°äº†è®ºæ–‡Table 1ä¸­çš„æ‰€æœ‰åŸºçº¿:

```python
# 1. ResNet50BlackBox
#    - æ ‡å‡†ResNet-50åˆ†ç±»å™¨
#    - é»‘ç›’æ¨¡å‹,æ— å¯è§£é‡Šæ€§

# 2. StandardCBM (Koh et al., ICML 2020)
#    - çº¿æ€§æ¦‚å¿µæŠ•å½± (å­˜åœ¨Linear Expressiveness Bottleneck)
#    - x -> features -> concepts -> predictions

# 3. PostHocCBM (Yuksekgonul et al., ICLR 2023)
#    - å†»ç»“backbone + çº¿æ€§æ¦‚å¿µæ¢é’ˆ
#    - æ®‹å·®è¿æ¥: features + concepts

# 4. DisDiffFNNC
#    - ç®€åŒ–ç‰ˆNS-Diff (æ— ç«¯åˆ°ç«¯è®­ç»ƒ)
#    - å†»ç»“æ‰©æ•£ç‰¹å¾ + ç®€å•æ¨¡ç³Šåˆ†ç±»å™¨
```

#### 3. **data/datasets.py** - æ•°æ®é›†åŠ è½½

æ”¯æŒä¸¤ä¸ªæ ‡å‡†æ•°æ®é›†:

```python
# 1. Shapes3DDataset
#    - 480,000å¼ å›¾åƒ
#    - 6ä¸ªground-truthå› å­
#    - å®Œç¾æ§åˆ¶å˜é‡,ç”¨äºå®šé‡éªŒè¯

# 2. CelebAHQDataset
#    - 30,000å¼ 256x256äººè„¸å›¾åƒ
#    - 8ä¸ªä¸»è¦å±æ€§ä½œä¸ºæ¦‚å¿µ
#    - çœŸå®å¤æ‚æµå½¢,æµ‹è¯•é²æ£’æ€§
```

**è¿”å›æ ¼å¼**: `(image, target, concepts)`
- `image`: å½’ä¸€åŒ–çš„å›¾åƒtensor [3, H, W]
- `target`: ç±»åˆ«æ ‡ç­¾ (int)
- `concepts`: æ¦‚å¿µå‘é‡ [num_concepts]

#### 4. **evaluation/metrics.py** - è¯„ä¼°æŒ‡æ ‡

å®ç°è®ºæ–‡4.1.3èŠ‚å®šä¹‰çš„æ‰€æœ‰æŒ‡æ ‡:

```python
# 1. compute_mig()
#    - Mutual Information Gap
#    - è¡¡é‡æ¦‚å¿µè§£è€¦ç¨‹åº¦
#    - MIG = (1/K) * âˆ‘_k [I(c_k; v_k^*) - max_{jâ‰ k^*} I(c_k; v_j)]

# 2. compute_intervention_success_rate()
#    - Intervention Success Rate (ISR)
#    - éªŒè¯åäº‹å®ç”Ÿæˆè´¨é‡
#    - ISR = (æˆåŠŸå¹²é¢„æ¬¡æ•° / æ€»å¹²é¢„æ¬¡æ•°) * 100%

# 3. compute_disentanglement_score()
#    - å¤šä¸ªè§£è€¦æŒ‡æ ‡: MIG, SAP, Modularity
#    - å…¨é¢è¯„ä¼°æ¦‚å¿µè´¨é‡
```

#### 5. **evaluation/visualization.py** - å¯è§†åŒ–å·¥å…·

ç”Ÿæˆè®ºæ–‡ä¸­çš„æ‰€æœ‰å›¾è¡¨:

```python
# 1. visualize_counterfactual_comparison()
#    - å¯¹åº”è®ºæ–‡Figure 2
#    - å±•ç¤ºåŸå§‹å›¾åƒ vs åäº‹å®å›¾åƒ
#    - æ˜¾ç¤ºæ¦‚å¿µå˜åŒ–

# 2. plot_performance_comparison()
#    - å¯¹åº”è®ºæ–‡Table 1
#    - å¤šæ¨¡å‹æ€§èƒ½å¯¹æ¯”æŸ±çŠ¶å›¾

# 3. visualize_concept_manifold()
#    - t-SNE/PCAå¯è§†åŒ–æ¦‚å¿µç©ºé—´
#    - éªŒè¯æµå½¢ç»“æ„

# 4. create_concept_intervention_grid()
#    - å±•ç¤ºæ¦‚å¿µè¿ç»­å¹²é¢„æ•ˆæœ
#    - 7æ­¥æ’å€¼ç½‘æ ¼
```

#### 6. **train.py** - è®­ç»ƒè„šæœ¬

ç»Ÿä¸€çš„è®­ç»ƒæ¡†æ¶,æ”¯æŒæ‰€æœ‰æ¨¡å‹:

```python
class Trainer:
    def train_epoch():
        # Algorithm 1çš„å®Œæ•´å®ç°
        # Phase 1-4: å‰å‘ä¼ æ’­ + æŸå¤±è®¡ç®— + åå‘ä¼ æ’­
        # Phase 5: å‘¨æœŸæ€§åäº‹å®éªŒè¯

    def evaluate():
        # è®¡ç®—æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡
        # Acc, MIG, ISR

    def _visualize_counterfactuals():
        # ç”ŸæˆTensorBoardå¯è§†åŒ–
```

**å‘½ä»¤è¡Œæ¥å£**:
```bash
python train.py \
    --model {ns_diff, resnet50, standard_cbm, posthoc_cbm, disdiff_fnnc} \
    --dataset {shapes3d, celeba-hq} \
    --epochs 100 \
    --batch_size 32 \
    --lambda_cls 1.0 \
    --lambda_ortho 0.1
```

#### 7. **experiments/run_all_experiments.py** - å®Œæ•´å®éªŒå¥—ä»¶

è‡ªåŠ¨åŒ–è¿è¡Œæ‰€æœ‰å®éªŒ:

```python
class ExperimentRunner:
    def run_baseline_comparison():
        # è¿è¡Œ5ä¸ªæ¨¡å‹å¯¹æ¯” (Table 1)
        # ç”Ÿæˆå¯¹æ¯”å›¾å’ŒLaTeXè¡¨æ ¼

    def run_ablation_study():
        # NS-Diffæ¶ˆèç ”ç©¶ (Table 1åº•éƒ¨)
        # w/o SMA, w/o Ortho, w/o DNSL

    def run_shapes3d_experiments():
        # Shapes3Dæ•°æ®é›†éªŒè¯

    def generate_counterfactual_visualizations():
        # ç”ŸæˆFigure 2çš„å¯è§†åŒ–
```

## ğŸ”¬ å®éªŒå¤ç°æµç¨‹

### Step 1: ç¯å¢ƒå‡†å¤‡

```bash
# åˆ›å»ºç¯å¢ƒ
conda create -n nsdiff python=3.9
conda activate nsdiff

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# æµ‹è¯•å®‰è£…
python test_installation.py
```

### Step 2: æ•°æ®å‡†å¤‡

```bash
# CelebA-HQ
./scripts/download_celeba_hq.sh /path/to/data

# Shapes3D
./scripts/download_shapes3d.sh /path/to/data
```

### Step 3: è¿è¡Œå•ä¸ªå®éªŒ

```bash
# NS-Diff
python train.py --model ns_diff --dataset celeba-hq \
    --data_path /path/to/celeba-hq \
    --image_dir /path/to/celeba-hq/images \
    --attr_file /path/to/celeba-hq/list_attr_celeba.txt \
    --epochs 100 --batch_size 32

# åŸºçº¿æ¨¡å‹
python train.py --model resnet50 --dataset celeba-hq ...
python train.py --model standard_cbm --dataset celeba-hq ...
```

### Step 4: è¿è¡Œå®Œæ•´å®éªŒå¥—ä»¶

```bash
# ä¿®æ”¹é…ç½®æ–‡ä»¶
vim experiments/config.json

# è¿è¡Œæ‰€æœ‰å®éªŒ
python experiments/run_all_experiments.py --config experiments/config.json
```

### Step 5: ç»“æœåˆ†æ

```bash
# æŸ¥çœ‹TensorBoardæ—¥å¿—
tensorboard --logdir ./experimental_results/logs

# ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
# è‡ªåŠ¨ç”Ÿæˆåœ¨ ./experimental_results/EXPERIMENTAL_REPORT.md
```

## ğŸ“Š é¢„æœŸè¾“å‡º

### è®­ç»ƒè¾“å‡ºç¤ºä¾‹

```
==================================================
Epoch 50/100
==================================================
Train - Loss: 0.3245, Acc: 89.3%, Ortho Loss: 0.0012
Test  - Loss: 0.3567, Acc: 87.8%, MIG: 0.78, ISR: 91.4%
âœ“ New best model saved! Acc: 87.8%
```

### ç”Ÿæˆçš„æ–‡ä»¶

```
experimental_results/
â”œâ”€â”€ baseline_comparison.csv         # åŸºçº¿å¯¹æ¯”æ•°æ®
â”œâ”€â”€ baseline_comparison.png         # å¯¹æ¯”å›¾è¡¨
â”œâ”€â”€ ablation_study.csv             # æ¶ˆèç ”ç©¶æ•°æ®
â”œâ”€â”€ ablation_study.png             # æ¶ˆèçƒ­å›¾
â”œâ”€â”€ counterfactual_concept_0.png   # åäº‹å®å¯è§†åŒ–
â”œâ”€â”€ counterfactual_concept_1.png
â”œâ”€â”€ shapes3d_results.csv           # Shapes3Dç»“æœ
â”œâ”€â”€ EXPERIMENTAL_REPORT.md         # æœ€ç»ˆæŠ¥å‘Š
â””â”€â”€ logs/                          # TensorBoardæ—¥å¿—
    â”œâ”€â”€ ns_diff/
    â”œâ”€â”€ resnet50/
    â””â”€â”€ ...
```

## ğŸ¯ å…³é”®å®ç°ç»†èŠ‚

### 1. Jacobianæ­£äº¤æ­£åˆ™åŒ– (Theorem 1)

```python
# è®¡ç®—æ¯ä¸ªæ¦‚å¿µå¯¹zçš„æ¢¯åº¦
jacobians = []
for k in range(num_concepts):
    grad = torch.autograd.grad(
        outputs=c[:, k].sum(),
        inputs=z,
        create_graph=True  # éœ€è¦äºŒé˜¶å¯¼æ•°
    )[0]
    jacobians.append(grad)

# å½’ä¸€åŒ–å¹¶è®¡ç®—GramçŸ©é˜µ
J_norm = F.normalize(torch.stack(jacobians, dim=1), p=2, dim=2)
gram = torch.bmm(J_norm, J_norm.transpose(1, 2))

# æœ€å°åŒ–éå¯¹è§’çº¿å…ƒç´ 
mask = ~torch.eye(num_concepts, dtype=torch.bool)
L_ortho = (gram[:, mask] ** 2).mean()
```

### 2. Product T-Normæ¨ç† (Eq. 3-4)

```python
# å¯¹æ•°ç©ºé—´å®ç°ä»¥ä¿æŒæ•°å€¼ç¨³å®š
log_mu = torch.log(mu + 1e-8)
weighted_log = torch.matmul(log_mu, rule_weights.t())
alpha = torch.exp(weighted_log / rule_weights.sum(dim=1).t())

# ä¿è¯æ¢¯åº¦æµé€š
# âˆ‚Î±_l/âˆ‚c_k = (âˆ_{mâ‰ k} Î¼_m) Â· âˆ‚Î¼_k/âˆ‚c_k â‰  0
```

### 3. åäº‹å®ç”Ÿæˆ

```python
# 1. è·å–åŸå§‹æ¦‚å¿µ
z = encoder(x)
c = sma(z)

# 2. å¹²é¢„æ¦‚å¿µ
c_prime = c.clone()
c_prime[:, target_idx] = target_value

# 3. ç”Ÿæˆåäº‹å®
x_cf = decoder(c_prime)

# 4. éªŒè¯å¹²é¢„æ•ˆæœ
z_cf = encoder(x_cf)
c_cf = sma(z_cf)
success = |c_cf[:, target_idx] - target_value| < threshold
```

## ğŸ”§ è°ƒè¯•æŠ€å·§

### 1. ç›‘æ§æ¢¯åº¦æµ

```python
# åœ¨è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ 
for name, param in model.named_parameters():
    if param.grad is not None:
        print(f"{name}: grad_norm={param.grad.norm():.4f}")
```

### 2. å¯è§†åŒ–æ¦‚å¿µç©ºé—´

```python
from evaluation.visualization import visualize_concept_manifold

visualize_concept_manifold(
    concepts=learned_concepts,
    labels=true_labels,
    concept_names=concept_names,
    method='tsne'
)
```

### 3. æ£€æŸ¥æ­£äº¤æ€§

```python
# è®¡ç®—æ¦‚å¿µé—´çš„ä½™å¼¦ç›¸ä¼¼åº¦
c_norm = F.normalize(concepts, p=2, dim=0)
similarity = torch.matmul(c_norm.t(), c_norm)
print(f"Off-diagonal max: {similarity.fill_diagonal_(0).abs().max():.4f}")
# åº”è¯¥æ¥è¿‘0
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 1. æ•°æ®åŠ è½½ä¼˜åŒ–

```python
train_loader = DataLoader(
    dataset,
    batch_size=32,
    num_workers=8,        # å¤šè¿›ç¨‹åŠ è½½
    pin_memory=True,      # åŠ é€ŸGPUä¼ è¾“
    prefetch_factor=2     # é¢„å–batch
)
```

### 2. æ··åˆç²¾åº¦è®­ç»ƒ

```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

with autocast():
    outputs = model(images)
    loss = criterion(outputs, targets)

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

### 3. æ¢¯åº¦ç´¯ç§¯

```python
# æ¨¡æ‹Ÿæ›´å¤§çš„batch size
accumulation_steps = 4
for i, (images, targets) in enumerate(train_loader):
    loss = model.compute_loss(images, targets) / accumulation_steps
    loss.backward()

    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

## ğŸ“ å­¦æœ¯ç”¨é€”

å¦‚æœæ‚¨ä½¿ç”¨æœ¬ä»£ç è¿›è¡Œç ”ç©¶,è¯·ç¡®ä¿:

1. âœ… å¼•ç”¨åŸè®ºæ–‡
2. âœ… æŠ¥å‘Šæ‰€æœ‰è¶…å‚æ•°
3. âœ… ä½¿ç”¨ç›¸åŒçš„æ•°æ®åˆ’åˆ†
4. âœ… è¿è¡Œå¤šæ¬¡å®éªŒå¹¶æŠ¥å‘Šæ ‡å‡†å·®
5. âœ… å¼€æºæ‚¨çš„ä»£ç å’Œç»“æœ

## ğŸ“ è·å–å¸®åŠ©

- **GitHub Issues**: æŠ¥å‘Šbugæˆ–è¯·æ±‚åŠŸèƒ½
- **Discussions**: æŠ€æœ¯è®¨è®ºå’Œé—®ç­”
- **Email**: ç´§æ€¥é—®é¢˜è”ç³»ä½œè€…

## ğŸš€ åç»­å·¥ä½œæ–¹å‘

1. **æ‰©å±•åˆ°æ›´å¤šæ¨¡æ€**: æ–‡æœ¬ã€éŸ³é¢‘ç­‰
2. **å¤§è§„æ¨¡æ•°æ®é›†**: ImageNet-1K
3. **åœ¨çº¿å­¦ä¹ **: å¢é‡æ¦‚å¿µå­¦ä¹ 
4. **å¤šä»»åŠ¡å­¦ä¹ **: å…±äº«æ¦‚å¿µç©ºé—´
5. **å› æœæ¨æ–­**: æ›´ä¸¥æ ¼çš„å› æœéªŒè¯

---

**ç¥æ‚¨å®éªŒé¡ºåˆ©! ğŸ‰**